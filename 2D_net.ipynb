{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation-models-pytorch in /Users/t-jun/future/.venv/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.16.1)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: timm==0.9.2 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\n",
      "Requirement already satisfied: tqdm in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\n",
      "Requirement already satisfied: pillow in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\n",
      "Requirement already satisfied: torch in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.1)\n",
      "Requirement already satisfied: munch in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.19.4)\n",
      "Requirement already satisfied: safetensors in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\n",
      "Requirement already satisfied: numpy in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.2)\n",
      "Requirement already satisfied: requests in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/t-jun/future/.venv/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional\n",
    "!pip install -U segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train_df.csv\")\n",
    "val_df = pd.read_csv(\"./data/val_df.csv\")\n",
    "test_df = pd.read_csv(\"./data/test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本データセットはラベル有りと無しがほぼ１：１になっているので、全てのデータを使用すると上手く学習が進まなかった為、\n",
    "# ラベル有りのデータのみで学習を行った。\n",
    "train_df = train_df[train_df.label == 1].reset_index(drop=True)\n",
    "val_df = val_df[val_df.label == 1].reset_index(drop=True)\n",
    "test_df = test_df[test_df.label == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>case_day</th>\n",
       "      <th>imgpath</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>hpix</th>\n",
       "      <th>wpix</th>\n",
       "      <th>labelpath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>case123_day20_slice_0065</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>case123_day20_slice_0066</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>case123_day20_slice_0067</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>case123_day20_slice_0068</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>case123_day20_slice_0069</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>38484</td>\n",
       "      <td>38484</td>\n",
       "      <td>case30_day0_slice_0133</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15055</th>\n",
       "      <td>38485</td>\n",
       "      <td>38485</td>\n",
       "      <td>case30_day0_slice_0134</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15056</th>\n",
       "      <td>38486</td>\n",
       "      <td>38486</td>\n",
       "      <td>case30_day0_slice_0135</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15057</th>\n",
       "      <td>38487</td>\n",
       "      <td>38487</td>\n",
       "      <td>case30_day0_slice_0136</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15058</th>\n",
       "      <td>38488</td>\n",
       "      <td>38488</td>\n",
       "      <td>case30_day0_slice_0137</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15059 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0                        id       case_day  \\\n",
       "0                64          64  case123_day20_slice_0065  case123_day20   \n",
       "1                65          65  case123_day20_slice_0066  case123_day20   \n",
       "2                66          66  case123_day20_slice_0067  case123_day20   \n",
       "3                67          67  case123_day20_slice_0068  case123_day20   \n",
       "4                68          68  case123_day20_slice_0069  case123_day20   \n",
       "...             ...         ...                       ...            ...   \n",
       "15054         38484       38484    case30_day0_slice_0133    case30_day0   \n",
       "15055         38485       38485    case30_day0_slice_0134    case30_day0   \n",
       "15056         38486       38486    case30_day0_slice_0135    case30_day0   \n",
       "15057         38487       38487    case30_day0_slice_0136    case30_day0   \n",
       "15058         38488       38488    case30_day0_slice_0137    case30_day0   \n",
       "\n",
       "                                                 imgpath  height  width  hpix  \\\n",
       "0      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "1      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "2      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "3      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "4      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "...                                                  ...     ...    ...   ...   \n",
       "15054  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "15055  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "15056  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "15057  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "15058  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "\n",
       "       wpix                                          labelpath  label  \n",
       "0       1.5  ./data/train/case123/case123_day20/label/case1...      1  \n",
       "1       1.5  ./data/train/case123/case123_day20/label/case1...      1  \n",
       "2       1.5  ./data/train/case123/case123_day20/label/case1...      1  \n",
       "3       1.5  ./data/train/case123/case123_day20/label/case1...      1  \n",
       "4       1.5  ./data/train/case123/case123_day20/label/case1...      1  \n",
       "...     ...                                                ...    ...  \n",
       "15054   1.5  ./data/train/case30/case30_day0/label/case30_d...      1  \n",
       "15055   1.5  ./data/train/case30/case30_day0/label/case30_d...      1  \n",
       "15056   1.5  ./data/train/case30/case30_day0/label/case30_d...      1  \n",
       "15057   1.5  ./data/train/case30/case30_day0/label/case30_d...      1  \n",
       "15058   1.5  ./data/train/case30/case30_day0/label/case30_d...      1  \n",
       "\n",
       "[15059 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>case_day</th>\n",
       "      <th>imgpath</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>hpix</th>\n",
       "      <th>wpix</th>\n",
       "      <th>labelpath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>case123_day20_slice_0003</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>case123_day20_slice_0004</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>case123_day20_slice_0005</td>\n",
       "      <td>case123_day20</td>\n",
       "      <td>./data/train/case123/case123_day20/scans/slice...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case123/case123_day20/label/case1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38491</th>\n",
       "      <td>38491</td>\n",
       "      <td>case30_day0_slice_0140</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38492</th>\n",
       "      <td>38492</td>\n",
       "      <td>case30_day0_slice_0141</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38493</th>\n",
       "      <td>38493</td>\n",
       "      <td>case30_day0_slice_0142</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38494</th>\n",
       "      <td>38494</td>\n",
       "      <td>case30_day0_slice_0143</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38495</th>\n",
       "      <td>38495</td>\n",
       "      <td>case30_day0_slice_0144</td>\n",
       "      <td>case30_day0</td>\n",
       "      <td>./data/train/case30/case30_day0/scans/slice_01...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>./data/train/case30/case30_day0/label/case30_d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38496 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                        id       case_day  \\\n",
       "0               0  case123_day20_slice_0001  case123_day20   \n",
       "1               1  case123_day20_slice_0002  case123_day20   \n",
       "2               2  case123_day20_slice_0003  case123_day20   \n",
       "3               3  case123_day20_slice_0004  case123_day20   \n",
       "4               4  case123_day20_slice_0005  case123_day20   \n",
       "...           ...                       ...            ...   \n",
       "38491       38491    case30_day0_slice_0140    case30_day0   \n",
       "38492       38492    case30_day0_slice_0141    case30_day0   \n",
       "38493       38493    case30_day0_slice_0142    case30_day0   \n",
       "38494       38494    case30_day0_slice_0143    case30_day0   \n",
       "38495       38495    case30_day0_slice_0144    case30_day0   \n",
       "\n",
       "                                                 imgpath  height  width  hpix  \\\n",
       "0      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "1      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "2      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "3      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "4      ./data/train/case123/case123_day20/scans/slice...     266    266   1.5   \n",
       "...                                                  ...     ...    ...   ...   \n",
       "38491  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "38492  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "38493  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "38494  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "38495  ./data/train/case30/case30_day0/scans/slice_01...     266    266   1.5   \n",
       "\n",
       "       wpix                                          labelpath  label  \n",
       "0       1.5  ./data/train/case123/case123_day20/label/case1...      0  \n",
       "1       1.5  ./data/train/case123/case123_day20/label/case1...      0  \n",
       "2       1.5  ./data/train/case123/case123_day20/label/case1...      0  \n",
       "3       1.5  ./data/train/case123/case123_day20/label/case1...      0  \n",
       "4       1.5  ./data/train/case123/case123_day20/label/case1...      0  \n",
       "...     ...                                                ...    ...  \n",
       "38491   1.5  ./data/train/case30/case30_day0/label/case30_d...      0  \n",
       "38492   1.5  ./data/train/case30/case30_day0/label/case30_d...      0  \n",
       "38493   1.5  ./data/train/case30/case30_day0/label/case30_d...      0  \n",
       "38494   1.5  ./data/train/case30/case30_day0/label/case30_d...      0  \n",
       "38495   1.5  ./data/train/case30/case30_day0/label/case30_d...      0  \n",
       "\n",
       "[38496 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/moddf.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの作成\n",
    "class Dataset(BaseDataset):\n",
    "    def __init__(self, df, transform = None, classes = None, augmentation = None):\n",
    "        self.imgpath_list = df.imgpath\n",
    "        self.labelpath_list = df.labelpath\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        imgpath = self.imgpath_list[i]\n",
    "        img = cv2.imread(imgpath)\n",
    "        img = cv2.resize(img, dsize=(256, 256))\n",
    "        img = img/255\n",
    "        img = torch.from_numpy(img.astype(np.float32)).clone()\n",
    "        img = img.permute(2, 0, 1)\n",
    "\n",
    "        labelpath = self.labelpath_list[i]\n",
    "        label = Image.open(labelpath)\n",
    "        label = np.asarray(label)\n",
    "        label = cv2.resize(label, dsize=(256, 256))\n",
    "        label = torch.from_numpy(label.astype(np.float32)).clone()\n",
    "        label = torch.nn.functional.one_hot(label.long(), num_classes=4)\n",
    "        label = label.to(torch.float32)\n",
    "        label = label.permute(2, 0, 1)\n",
    "\n",
    "        data = {\"img\": img, \"label\": label}\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgpath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_dataset = Dataset(df)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_dataset = Dataset(val_df)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=4,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_dataset = Dataset(test_df)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unetの構築\n",
    "nn.ModuleListを使用することで短く描くことも可能だが、可読性が低下する為以下のように書く\n",
    "今回、デコーダーのup-Convolution（高さと幅を2倍にしつつ、チャンネル数を半分にする）については以下の方法で実装している\n",
    "* nn.Upsampleを使用してup-Convolutionを行い、直後にnn.Conv2d（カーネルサイズは2*2を採用しているが、1*1でも良い）でチャンネル数を半分にする\n",
    "- 以下の2つの方法でも実装可能\n",
    "* up-Convolutionの直前でConvolutionブロックでチャンネル数を半分にし、その後nn.Upsampleを使用してup-Convolutionを行う\n",
    "* nn.ConvTranspose2dを使用してup-Convolutionを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.rl = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.rl(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl(x)\n",
    "        return x\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 2, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "class UNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.TCB1 = TwoConvBlock(3, 64, 64)\n",
    "        self.TCB2 = TwoConvBlock(64, 128, 128)\n",
    "        self.TCB3 = TwoConvBlock(128, 256, 256)\n",
    "        self.TCB4 = TwoConvBlock(256, 512, 512)\n",
    "        self.TCB5 = TwoConvBlock(512, 1024, 1024)\n",
    "        self.TCB6 = TwoConvBlock(1024, 512, 512)\n",
    "        self.TCB7 = TwoConvBlock(512, 256, 256)\n",
    "        self.TCB8 = TwoConvBlock(256, 128, 128)\n",
    "        self.TCB9 = TwoConvBlock(128, 64, 64)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride = 2)\n",
    "        \n",
    "        self.UC1 = UpConv(1024, 512) \n",
    "        self.UC2 = UpConv(512, 256) \n",
    "        self.UC3 = UpConv(256, 128) \n",
    "        self.UC4= UpConv(128, 64)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 4, kernel_size = 1)\n",
    "        self.soft = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.TCB1(x)\n",
    "        x1 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB2(x)\n",
    "        x2 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB3(x)\n",
    "        x3 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB4(x)\n",
    "        x4 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB5(x)\n",
    "\n",
    "        x = self.UC1(x)\n",
    "        x = torch.cat([x4, x], dim = 1)\n",
    "        x = self.TCB6(x)\n",
    "\n",
    "        x = self.UC2(x)\n",
    "        x = torch.cat([x3, x], dim = 1)\n",
    "        x = self.TCB7(x)\n",
    "\n",
    "        x = self.UC3(x)\n",
    "        x = torch.cat([x2, x], dim = 1)\n",
    "        x = self.TCB8(x)\n",
    "\n",
    "        x = self.UC4(x)\n",
    "        x = torch.cat([x1, x], dim = 1)\n",
    "        x = self.TCB9(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU、最適化アルゴリズムの設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet = UNet_2D().to(device)\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "# 損失はTversky LossとBCEWithLogits Lossの平均とした。これらの関数は損失関数内でソフトマックス関数を\n",
    "# 処理する為、UNetの最後にソフトマックス関数を適用しない\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False)\n",
    "BCELoss = UNet_2D().to(device)\n",
    "def criterion(pred, target):\n",
    "    return 0.5*BCELoss(pred, target) + 0.5*TverskyLoss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/t-jun/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/t-jun/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'Dataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/t-jun/future/x-unet/2D_net.ipynb セル 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/t-jun/future/x-unet/2D_net.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/t-jun/future/x-unet/2D_net.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m unet\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/t-jun/future/x-unet/2D_net.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/t-jun/future/x-unet/2D_net.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   inputs, labels \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device), data[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/t-jun/future/x-unet/2D_net.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/future/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/future/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/future/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.1/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習を行う\n",
    "history = {\"train_loss\": []}\n",
    "n = 0\n",
    "m = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "  train_loss = 0\n",
    "  val_loss = 0\n",
    "\n",
    "  unet.train()\n",
    "  for i, data in enumerate(train_loader):\n",
    "    inputs, labels = data[\"img\"].to(device), data[\"label\"].to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = unet(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    history[\"train_loss\"].append(loss.item())\n",
    "    n += 1\n",
    "    if i % ((len(df)//BATCH_SIZE)//10) == (len(df)//BATCH_SIZE)//10 - 1:\n",
    "      print(f\"epoch:{epoch+1}  index:{i+1}  train_loss:{train_loss/n:.5f}\")\n",
    "      n = 0\n",
    "      train_loss = 0\n",
    "      train_acc = 0\n",
    "\n",
    "\n",
    "  unet.eval()\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "      inputs, labels = data[\"img\"].to(device), data[\"label\"].to(device)\n",
    "      outputs = unet(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_loss += loss.item()\n",
    "      m += 1\n",
    "      if i % (len(val_df)//BATCH_SIZE) == len(val_df)//BATCH_SIZE - 1:\n",
    "        print(f\"epoch:{epoch+1}  index:{i+1}  val_loss:{val_loss/m:.5f}\")\n",
    "        m = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "  torch.save(unet.state_dict(), f\"./train_{epoch+1}.pth\")\n",
    "print(\"finish training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失の推移をプロットする\n",
    "plt.plot(history[\"train_loss\"])\n",
    "plt.xlabel('batch')\n",
    "plt.ylabel('loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "future",
   "language": "python",
   "name": "future"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
